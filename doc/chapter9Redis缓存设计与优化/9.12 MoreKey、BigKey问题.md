# MoreKey

这里演示使用测试数据100W

## 1.生成100W条Redis数据写入到/tmp目录下的redisTest.txt文件中。

```shell
[root@redis ~]# for((i=1;i<=100*10000;i++)); do echo "set k$i v$i" >> /tmp/redisTest.txt ; done;
[root@redis ~]# more /tmp/redisTest.txt 
set k1 v1
set k2 v2
set k3 v3
set k4 v4
set k5 v5
set k6 v6
set k7 v7
set k8 v8
set k9 v9
set k10 v10
set k11 v11
set k12 v12
set k13 v13
set k14 v14
set k15 v15
set k16 v16
set k17 v17
......
```

## 2.通过redis提供的管道-pipe命令插入100W数据

```shell
[root@redis ~]# cat /tmp/redisTest.txt |/opt/redis-6.2.6/src/redis-cli -h 127.0.0.1 -p 6379 -a root --pipe
Warning: Using a password with '-a' or '-u' option on the command line interface may not be safe.
All data transferred. Waiting for the last reply...
Last reply received from server.
errors: 0, replies: 1000000
[root@redis ~]# redis-cli -a root
Warning: Using a password with '-a' or '-u' option on the command line interface may not be safe.
127.0.0.1:6379> get k1000000
"v1000000"
```

## 3.MoreKey问题：大批量往redis里面插入2000W测试数据key，如何遍历这些key呢？

可能立马想到的就是`keys *`命令了。

对Redis稍微有点使用经验的人都知道线上是不能执行keys*相关命令的。虽然其模糊匹配功能使用非常方便也很强大，在小数据量情况下使用没什么问题，数据量大会导致Redis锁住及CPU飙升，在生产环境建议禁用！

由于redis是单线程的，keys算法是遍历算法，时间复杂度是O(n),如果实例中有千万级以上的key，这个指令就会导致redis服务卡顿，所有读写Redis的其它的指令都会被延后甚至会超时报错，可能会引起缓存雪崩甚至数据库宕机。

## 4.生产上限制keys \* /flushdb/flushall 等危险命令以防止误删误用

通过redis.conf配置设置禁用这些命令，在SECURITY这一项中

![image-20240317195010647](https://gitee.com/dongguo4812_admin/image/raw/master/image/202403171950661.png)

通过将其重命名为一个空字符串来禁用一个命令。

```shell
rename-command keys ""
rename-command flushdb ""
rename-command flushall ""
```

修改后可能重启Redis失败，因为AOF中记录了以上命令，在Redis重启并尝试重新执行AOF文件中的命令时，会遇到问题，因为那些被禁用的命令现在不再存在。需要重写一下AOF文件。

```shell
redis-cli --appendonly yes --appendfilename appendonly.aof rewrite
```



## 5.大数据量不采用keys \* 遍历避免卡顿，那该如何？

​	`SCAN cursor [MATCH pattern`][COUNT count]

- cursor-游标。

- pattern-匹配的模式。

- count-指定从数据集里返回多少元素，默认值为10。



SCAN命令是一个基于游标的迭代器，每次被调用之后，都会向用户返回一个新的游标。，用户在下次迭代时需要使用这个新游标作为SCAN命令的游标参数，以此来延续之前的迭代过程。不保证每次执行都返回某个给定数量的元素，支持模糊查询。一次返回的数量不可控，只能是大概率符合count参数

SCAN命令用于迭代redis数据库中的数据库键，类似于mysql中的limit但又不完全相同。

### SCAN返回一个包含两个元素的数组，

第一个元素是用于进行下一次迭代的新游标，

第二个元素则是一个数组，这个数组中包含了所有被迭代的元素。如果新游标返回零表示迭代已结束。



### SCAN的遍历顺序

它不是从第一维数组的第零位一直遍历到末尾，而是采用了高位进位加法来遍历。之所以使用这样特殊的方式进行遍历，是考虑到字典的扩容和缩容时避免槽位的遍历重复和遗漏。



指定返回20个元素，但是实际返回的是20个左右的元素

```java
127.0.0.1:6379> SCAN 0 match k* count 20
1) "98304"
2)  1) "k901150"
    2) "k620970"
    3) "k532756"
    4) "k806557"
    5) "k573867"
    6) "k241219"
    7) "k138033"
    8) "k849846"
    9) "k632555"
   10) "k555235"
   11) "k369021"
   12) "k342091"
   13) "k50917"
   14) "k118462"
   15) "k930663"
   16) "k601674"
   17) "k240372"
   18) "k566649"
   19) "k949615"
   20) "k568360"
   21) "k554763"
   22) "k146203"
127.0.0.1:6379> SCAN 98304 match k* count 20
1) "212992"
2)  1) "k837234"
    2) "k537080"
    3) "k308944"
    4) "k299680"
    5) "k204081"
    6) "k49503"
    7) "k794676"
    8) "k708466"
    9) "k617817"
   10) "k110838"
   11) "k942032"
   12) "k896064"
   13) "k620070"
   14) "k124269"
   15) "k304126"
   16) "k235907"
   17) "k14268"
   18) "k845848"
   19) "k773903"
   20) "k748508"
   21) "k651027"
   22) "k623382"
   23) "k26525"
   24) "k196937"
```

# BigKey

## 1.多大算大key

![image-20240317203405825](https://gitee.com/dongguo4812_admin/image/raw/master/image/202403172034310.png)

string的value最大可达到512MB，但是10KB就是bigkey

list、hash、set和zset,个数超过5000就是bigkey



## 2.BigKey有哪些危害

- 内存不均，集群迁移困难

  **内存不均**：当 Redis 实例中存在 BigKey 时，这些键会占用大量的内存。如果 BigKey 分布不均，发生数据倾斜，就会导致不同实例之间的内存使用差异显著，影响整体性能和资源利用率。

  **集群迁移困难**：在 Redis 集群环境中，当某个节点需要下线或迁移时，BigKey 会成为迁移的瓶颈。因为迁移一个 BigKey 涉及大量的数据传输和同步，这会增加迁移的时间和复杂性，甚至可能导致迁移失败

- 超时删除，大key删除作梗

​		**超时删除**：当尝试删除一个 BigKey 时，Redis 需要花费更长的时间来完成删除操作。如果删除操作耗		时过长，可能会导致其他命令或操作被阻塞或超时，影响整体性能。

​		**删除作梗**：BigKey 的删除还可能引发其他问题。例如，在删除过程中，如果 Redis 实例突然崩溃或重		启，可能导致数据不一致或丢失。此外，如果 BigKey 的删除操作频繁或大量进行，还可能对 Redis 的		稳定性造成威胁。

- 网络流量阻塞

​		**网络流量增加**：BigKey 的读取和写入操作会产生大量的网络流量。因为 BigKey 本身数据量大，所以		在传输过程中会占用更多的网络带宽。这可能导致网络拥堵，影响其他服务的正常运行。

​		**阻塞其他操作**：当 Redis 服务器处理 BigKey 的请求时，可能会阻塞其他请求的处理。因为 BigKey 的		处理通常需要更多的 CPU 和内存资源，这可能导致其他请求被延迟或超时。

## 3.产生的场景

比如微博粉丝列表，典型案例粉丝逐步递增，达到几千万。

比如汇总统计，几年内的报表。

## 4.如何发现BigKey

### `redis-cli --bigkeys`

给出每种数据结构TOP 1 的bigkey，同时给出每种数据类型的键值个数与平均大小。

```shell
[root@redis ~]# redis-cli -a root --bigkeys
Warning: Using a password with '-a' or '-u' option on the command line interface may not be safe.

# Scanning the entire keyspace to find biggest keys as well as
# average sizes per key type.  You can use -i 0.1 to sleep 0.1 sec
# per 100 SCAN commands (not usually needed).

[00.00%] Biggest string found so far '"k901150"' with 7 bytes
[03.14%] Biggest string found so far '"redis:game:sign:destKey"' with 126 bytes
[03.61%] Biggest hash   found so far '"redis:redPackage:user:6e8a10064527459887e545e43c722426"' with 5 fields
[11.81%] Biggest set    found so far '"redis:wechat:1004:1001"' with 1 members
[16.58%] Biggest list   found so far '"list"' with 3 items
[22.17%] Biggest list   found so far '"redis:jhs"' with 20 items
[32.75%] Biggest set    found so far '"redis:white:list"' with 200 members
[35.08%] Biggest string found so far '"redis:user:bloomFilter:5"' with 65306841 bytes
[62.73%] Biggest zset   found so far '"zset"' with 4 members
[99.99%] Sampled 1000000 keys so far

-------- summary -------

Sampled 1000042 keys in the keyspace!
Total key length in bytes is 6889611 (avg len 6.89)

Biggest   list found '"redis:jhs"' has 20 items
Biggest   hash found '"redis:redPackage:user:6e8a10064527459887e545e43c722426"' has 5 fields
Biggest string found '"redis:user:bloomFilter:5"' has 65306841 bytes
Biggest    set found '"redis:white:list"' has 200 members
Biggest   zset found '"zset"' has 4 members

2 lists with 23 items (00.00% of keys, avg size 11.50)
4 hashs with 12 fields (00.00% of keys, avg size 3.00)
1000026 strings with 334320270 bytes (100.00% of keys, avg size 334.31)
0 streams with 0 entries (00.00% of keys, avg size 0.00)
8 sets with 209 members (00.00% of keys, avg size 26.12)
2 zsets with 8 members (00.00% of keys, avg size 4.00)

```

命令提示我们可以使用 -i 0.1每扫描 100 个键之后就休眠0.1秒，避免对 Redis 服务器的性能造成过大的影响：

```shell
# Scanning the entire keyspace to find biggest keys as well as
# average sizes per key type.  You can use -i 0.1 to sleep 0.1 sec
# per 100 SCAN commands (not usually needed).
```



如果想要查询大于10kb的所有key，需要使用MEMORY USAGE来计算每个键值的字节数

### MEMORY USAGE（不推荐占用内存）

`MEMORY USAGE key [SAMPLES count] `  获取指定键（key）在Redis内存中的近似大小。

```java
127.0.0.1:6379> MEMORY USAGE k100
(integer) 54
```

用于获取与给定键（key）相关联的内存使用情况。

- `key`：要查询其内存使用情况的键。
- `SAMPLES count`：这是一个可选参数，用于指定采样次数。默认情况下，Redis 会使用多个样本来估算键的内存使用情况，以获得更准确的结果。通过增加样本数量，你可以提高估算的准确性，但也会增加命令的执行时间。

这个命令返回的结果是一个整数，表示键在 Redis 中所占用的内存大小（以字节为单位）。这个大小包括键本身、值以及与之相关的任何元数据或开销。

需要注意的是，`MEMORY USAGE` 命令返回的是估算值，而不是精确值。



对于string可以使用`STRLEN key`查看字符串的长度，再确定占用的内存大小

对于集合比如list可以使用`LLEN key`查看元素的个数。

### scan扫描

使用代码，利用scan扫描redis中的所有key，利用STRLEN 、LLEN 等命令判断key的长度（不推荐使用MEMORY USAGE）

### 第三方工具

如redis-rdb-tools分析RDB快照文件，全面分析内存使用情况。

## 5.如何删除bigkey

### 对于string类型

数据量小的可以使用del，如果数据量大的就需要使用unlink。

### 对于hash类型

使用hscan每次获取少量field-value,再使用hdel删除每个field

每次迭代key的100个field-value，删除field，最后删除key

![image-20240317210931768](https://gitee.com/dongguo4812_admin/image/raw/master/image/202403172109748.png)

### 对于list类型

使用ltrim渐进式逐步删除，直到全部删除完成

分多次将bigkey逐步删除。

![image-20240317211413682](https://gitee.com/dongguo4812_admin/image/raw/master/image/202403172114022.png)

![image-20240317211328358](https://gitee.com/dongguo4812_admin/image/raw/master/image/202403172113580.png)

### 对于set类型

使用sscan每次获取部分元素，再使用srem命令删除每个元素

![image-20240317211542828](https://gitee.com/dongguo4812_admin/image/raw/master/image/202403172115770.png)

![image-20240317211551869](https://gitee.com/dongguo4812_admin/image/raw/master/image/202403172115898.png)

### 对于zset类型

使用zscan每次获取部分元素，再使用ZREMRANGEBYRANK命令删除每个元素

![image-20240317211811024](https://gitee.com/dongguo4812_admin/image/raw/master/image/202403172118929.png)

![image-20240317211825138](https://gitee.com/dongguo4812_admin/image/raw/master/image/202403172118156.png)

# BigKey生产调优

redis.conf配置文件LAZY FREEING相关说明

Redis有两种删除key的方式，del（阻塞）和unlink（非阻塞）

![image-20240317213604718](https://gitee.com/dongguo4812_admin/image/raw/master/image/202403172136994.png)

## 优化配置

![image-20240317213844301](https://gitee.com/dongguo4812_admin/image/raw/master/image/202403172138578.png)

### lazyfree-lazy-server-del

在 Redis 服务器执行某些操作时是否使用惰性删除（lazy free）机制来处理已存在的键。

当这个选项设置为 `yes` 时，Redis 会在处理一些指令（比如 `RENAME`）时，如果目标键已经存在，那么 Redis 会使用惰性删除机制来删除这个目标键。惰性删除意味着 Redis 不会立即释放键占用的内存，而是将这个操作放到后台的 I/O 线程中异步执行。这样做的好处是，它可以避免阻塞主线程，从而提高 Redis 的响应性能和吞吐量。

这个选项特别有用在处理大键（big key）时。大键的删除操作可能会消耗较多的 CPU 时间和内存资源，如果直接在主线程中执行，可能会严重影响 Redis 的性能。通过使用惰性删除机制，Redis 可以将这类耗时的操作放到后台处理，从而保持主线程的高性能。

### replica-lazy-flush

控制 Redis 在从节点（replica 或 slave）上执行 `FLUSHDB` 或 `FLUSHALL` 命令时的行为。

当 `replica-lazy-flush` 设置为 `yes` 时，如果从节点接收到 `FLUSHDB` 或 `FLUSHALL` 命令，Redis 不会立即删除所有的键，而是将这些键标记为待删除，并在后续的同步过程中逐渐地、异步地删除它们。这种方式可以避免从节点在删除大量键时产生过多的阻塞，影响性能。

`eplica-lazy-flush` 选项仅适用于从节点。对于主节点，执行 `FLUSHDB` 或 `FLUSHALL` 命令时，Redis 会立即删除所有的键，不会使用惰性删除的方式。

### lazyfree-lazy-user-del

用于控制 `DEL` 命令的行为。当这个选项设置为 `yes` 时，`DEL` 命令会表现得类似于 `UNLINK` 命令，即它会以非阻塞的方式删除键。

具体来说，默认情况下，当你使用 `DEL` 命令删除一个键时，Redis 会立即释放该键所占用的内存。但是，如果删除的键是一个大键（包含大量的数据），那么这个过程可能会消耗较多的 CPU 时间和内存资源，从而导致 Redis 的性能下降。

为了避免这种情况，Redis 提供了 `UNLINK` 命令，它会以非阻塞的方式删除键。当使用 `UNLINK` 命令时，Redis 不会立即释放键占用的内存，而是将删除操作放到后台的 I/O 线程中异步执行。这样，主线程就不会被阻塞，Redis 可以继续处理其他的命令。

`lazyfree-lazy-user-del` 选项就是用来让 `DEL` 命令也具有 `UNLINK` 命令的这种非阻塞删除特性的。当这个选项设置为 `yes` 时，`DEL` 命令就会表现得像 `UNLINK` 命令一样，以非阻塞的方式删除键。这对于处理大键特别有用，可以避免删除操作对 Redis 性能的影响。