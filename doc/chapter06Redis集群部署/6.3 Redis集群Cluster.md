通过哨兵模式集群的配置，我们可以看出哨兵集群模式是基于主从模式的，哨兵模式具有所有主从的优点。

哨兵模式是主从模式的升级，实现了自动化的故障恢复。但哨兵模式的缺点也很明显，Redis较难实现支持在线扩容，在集群容量达到上限时在线扩容会变得很复杂。

实现哨兵模式的配置也不简单，甚至有些繁琐，于是就有了Redis Cluster集群。Redis Cluster是官方的Redis集群实现。

Redis Cluster集群是一个由多个主从节点组成的分布式服务器群，它具有复制、高可用和分片特性。

Redis集群将所有数据存储区域划分为16384个槽位(slots)，每个节点负责一部分槽位，槽位的信息存储于每个节点中。Redis集群要将每个节点设置成集群模式，它没有中心节点，可水平扩展，它的性能和高可用性均优于主从模式和哨兵模式，而且集群配置非常简单。

Redis集群架构图如下图所示。

![image-20240306192928018](https://gitee.com/dongguo4812_admin/image/raw/master/image/202403061929227.png)

# 作用

 1.redis集群可以支持多个master 每个master又可以挂载多个slave

​		实现读写分离， 支持数据的高可用 ，  支持海量数据的读写存储操作

2.由于cluster自带sentinel的故障转移机制，内置了高可用的支持，无需再去使用哨兵功能

3.客户端与redis的节点连接，不再需要连接集群中所有的节点，只需要任意连接集群中的一个可用节点即可

4.槽位slot负责分配到各个物理服务节点，由对应的集群来负责维护节点，插槽和数据之间的关系

# 集群算法

## Redis集群的槽位slot

Redis集群没有使用一致性hash算法，而是引入了哈希槽的概念。

Redis集群有16384个哈希槽，每个key通过CRC16校验后对16384取模来决定放置哪个槽。集群的每个节点负责一部分hash槽，举个例子，比如当前集群有3个节点那么：

![image-20240306194605805](https://gitee.com/dongguo4812_admin/image/raw/master/image/202403061946695.png)

## Redis集群的分片

使用Redis集群时我们会将存储的数据分散到多台redis机器上，这称为分片。简言之，集群中的每个Redis实例都被认为是整个数据的一个分片。

### 如何找到给定key的分片

为了找到给定key的分片，我们对key进行CRC16(key)算法处理并通过对总分片数量取模。然后使用确定性哈希函数，这意味着给定的key将多次始终映射到同一个分片，我们可以推断将来读取特定key的位置。

## 哈希槽和分片的优势

方便扩缩容和数据分派查找

1. **添加新节点**：如果想向集群中添加一个新节点（例如节点D），需要从现有节点（例如节点A、B、C）中取出部分哈希槽并分配给新节点D。这个过程可以通过Redis的`CLUSTER ADDSLOTS`命令完成。

2. **删除节点**：如果想从集群中删除一个节点（例如节点A），您需要先将节点A中的所有哈希槽移动到其他节点（例如节点B和C）上。这可以通过Redis的`CLUSTER DELSLOTS`和`CLUSTER SETSLOT`命令完成。一旦节点A中的所有槽都被移动走，它就不再负责任何数据，此时可以安全地将其从集群中移除。

3. **重新分配哈希槽**：即使集群在运行过程中，也可以根据需要重新分配哈希槽。例如，如果某个节点因为硬件故障或其他原因变得不可用，可以将该节点的哈希槽重新分配到其他健康节点上。这个过程同样不会导致服务中断，因为Redis集群在处理哈希槽的移动时，会确保相关的键值对在新的节点上可用。

   所以无论添加删除或者改变某个节点的哈希槽的数量都不会造成集群不可用的状态。

## slot槽位映射的三种方案

决定槽位落到那个分区上的算法，推荐哈希槽方案。

### 哈希取余分区

假设有3台机器构成一个集群，用户每次读写操作都是根据公式：hash(key)%N个机器台数，计算出哈希值，用来决定数据映射到哪一个节点上。

![image-20240306201521468](https://gitee.com/dongguo4812_admin/image/raw/master/image/202403062015070.png)

#### 优点：

简单粗暴，直接有效，只需要预估好数据规划好节点，例如3台、8台、10台，就能保证一段时间的数据支撑。使用Hash算法让固定的一部分请求落到同一台服务器上，这样每台服务器固定处理一部分请求(并维护这些请求的信息），起到负载均衡+分而治之的作用。

#### 缺点：

原来规划好的节点，进行扩容或者缩容就比较麻烦了，不管扩缩，每次数据变动导致节点有变动，映射关系需要重新进行计算，在服务器个数固定不变时没有问题，如果需要弹性扩容或故障停机的情况下，原来的取模公式就会发生变化：Hash(key)/3会变成Hash(key)/?。此时地址经过取余运算的结果将发生很大变化，根据公式获取的服务器也会变得不可控。某个redis机器宕机了，由于节点数量变化，会导致hash取余全部数据重新洗牌。

### 一致性哈希算法分区

用于解决分布式系统中的数据分布问题。一致性哈希算法的主要特点是，在节点（例如服务器）增加或减少时，它能够尽可能少地改变已存在的键值对到节点的映射关系，从而减少数据的迁移量。

一致性哈希算法主要包括以下三个步骤：

#### 1.构建一致性哈希环

一致性哈希算法必然有个hash函数并按照算法产生hash值，这个算法的所有可能哈希值会构成一个全量集，这个集合可以成为一个hash空间[0，2へ32-1]，这个是一个线性空间，但是在算法中，我们通过适当的逻辑控制将它首尾相连（0=2へ32），这样让它逻辑上形成了一个环形空间。

它也是按照使用取模的方法，一致性Hash算法是对2^32取模，简单来说，一致性Hash算法将整个哈希值空间组织成一个虚拟的圆环，如假设某哈希函数H的值空间为0-2^32-1(即哈希值是一个32位无符号整形），整个哈希环如下图：

整个空间按顺时针方向组织，圆环的正上方的点代表0，0点右侧的第一个点代表1，以此类推，2、3、4、……直到2へ32-1，也就是说0点左侧的第一个点代表2へ32-1，我们把这个由2へ32个点组成的圆环称为Hash环。

![image-20240306203946253](https://gitee.com/dongguo4812_admin/image/raw/master/image/202403062039200.png)

#### 2.redis服务器ip节点映射

将集群中各个IP节点映射到环上的某一个位置。

将各个服务器使用Hash进行一个哈希，具体可以选择服务器的IP或主机名作为关键字进行哈希，这样每台机器就能确定其在哈希环上的位置。假如4个节点NodeA、B、C、D，节点的位置是由IP地址经过哈希函数计算(hash(ip))得到的，如下:

![image-20240306204128536](https://gitee.com/dongguo4812_admin/image/raw/master/image/202403062041462.png)

#### 3.key在服务器的落键规则

当我们需要存储一个kv键值对时，首先计算key的hash值，hash(key)，将这个key使用相同的函数Hash计算出哈希值并确定此数据在环上的位置，从此位置沿环顺时针查找，第一台遇到的服务器就是其应该定位到的服务器，并将该键值对存储在该节点上。

如我们有Object A、Object B、Object C、Object D四个数据对象，经过哈希计算后，在环空间上的位置如下：根据一致性Hash算法，数据A会被定为到Node A上，B被定为到Node B上，C被定为到Node C上，D被定为到Node D上。

![image-20240306204901954](https://gitee.com/dongguo4812_admin/image/raw/master/image/202403062049441.png)

#### 优点

##### 容错性

假设Node C宕机，可以看到此时对象A、B、D不会受到影响。一般的，在一致性Hash算法中，如果一台服务器不可用，则受影响的数据仅仅是此服务器到其环空间中前一台服务器（即沿着逆时针方向行走遇到的第一台服务器）之间数据，其它不会受到影响。简单说，就是C挂了，受到影响的只是B、C之间的数据且这些数据会转移到D进行存储。

![image-20240306205358766](https://gitee.com/dongguo4812_admin/image/raw/master/image/202403062053688.png)

##### 扩展性

数据量增加了，需要增加一台节点NodeX，X的位置在A和B之间，那收到影响的也就是A到X之间的数据，重新把A到X的数据录入到X上即可，不会导致hash取余全部数据重新洗牌。

![image-20240306205428692](https://gitee.com/dongguo4812_admin/image/raw/master/image/202403062054716.png)

#### 缺点

一致性哈希算法的数据倾斜问题

一致性Hash算法在服务节点太少时，容易因为节点分布不均匀而造成数据倾斜（被缓存的对象大部分集中缓存在某一台服务器上）问题，例如系统中只有两台服务器：

![image-20240306205549486](https://gitee.com/dongguo4812_admin/image/raw/master/image/202403062055362.png)

### 哈希槽分区

Redis集群没有使用一致性hash算法，而是引入了哈希槽的概念，解决一致性哈希算法的数据倾斜问题。

哈希槽实质就是一个数组，数组[0,2へ14-1]形成hash slot空间。

解决均匀分配的问题，在数据和节点之间又加入了一层，把这层称为哈希槽(slot)，用于管理数据和节点之间的关系，现在就相当于节点上放的是槽，槽里放的是数据。

![image-20240306205852207](https://gitee.com/dongguo4812_admin/image/raw/master/image/202403062058604.png)

槽解决的是粒度问题，相当于把粒度变大了，这样便于数据移动。哈希解决的是映射问题，使用key的哈希值来计算所在的槽，便于数据分配

一个集群只能有16384个槽，编号0-16383（0-2へ14-1）。这些槽会分配给集群中的所有主节点，分配策略没有要求。集群会记录节点和槽的对应关系，解决了节点和槽的关系后，接下来就需要对key求哈希值，然后对16384取模，余数是几key就落入对应的槽里。HASH_SLOT=CRC16(key)mod 16384。以槽为单位移动数据，因为槽的数目是固定的，处理起来比较容易，这样数据移动问题就解决了。

#### 哈希槽的计算

Redis集群中内置了16384个哈希槽，redis会根据节点数量大致均等的将哈希槽映射到不同的节点。当需要在Redis集群中放置一个key-value时，redis先对key使用crc16算法算出一个结果然后用结果对16384求余数[CRC16（key)% 16384]，这样每个key 都会对应一个编号在0-16383之间的哈希槽，也就是映射到某个节点上。

如下代码，key之A、B在Node2，key之C落在Node3上

![image-20240306210204589](https://gitee.com/dongguo4812_admin/image/raw/master/image/202403062102235.png)

#### 为什么redis集群的最大槽数是16384个？

Redis集群并没有使用一致性hash而是引入了哈希槽的概念。Redis集群有16384个哈希槽，每个key通过CRC16校验后对16384取模来决定放置哪个槽，集群的每个节点负责一部分hash槽。但为什么哈希槽的数量是16384（2^14）个呢？

CRC16算法产生的hash值有16bit，该算法可以产生2^16=65536个值。换句话说值是分布在0~65535之间，有更大的65536不用为什么只用16384就够?作者在做mod运算的时候，为什么不mod65536,而选择mod16384?

HASH_SLOT=CRC16(key)mod 65536为什么没启用？



在github同样有人提出这个问题：[why redis-cluster use 16384 slots?](https://github.com/redis/redis/issues/2576)

Redis的作者回答：

正常的心跳数据包带有节点的完整配置，可以用幂等方式用旧的节点替换旧节点，以便更新旧的配置。

这意味着它们包含原始节点的插槽配置，该节点使用2k的空间和16k的插槽，但是会使用8k的空间（使用65k的插槽）。

同时，由于其他设计折衷，Redis集群不太可能扩展到1000个以上的主节点。

因此16k处于正确的范围内，以确保每个主机具有足够的插槽，最多可容纳1000个矩阵，但数量足够少，可以轻松地将插槽配置作为原始位图传播。请注意，在小型群集中，位图将难以压缩，因为当N较小时，位图将设置的slot/N位占设置位的很大百分比。

![image-20240306210820018](https://gitee.com/dongguo4812_admin/image/raw/master/image/202403062108061.png)

（1）如果槽位为65536，发送心跳信息的消息头达8k，发送的心跳包过于庞大。

在消息头中最占空间的是myslots[CLUSTER_SLOTS/8]。当槽位为65536时，这块的大小是：65536=8=1024=8kb

在消息头中最占空间的是myslots[CLUSTER_SLOTS/8]。当槽位为16384时，这块的大小是：16384=8=1024=2kb

因为每秒钟，redis节点需要发送一定数量的ping消息作为心跳包，如果槽位为65536，这个ping消息的消息头太大了，浪费带宽。

（2）redis的集群主节点数量基本不可能超过1000个。

集群节点越多，心跳包的消息体内携带的数据越多。如果节点过1000个，也会导致网络拥堵。

因此redis作者不建议redis cluster节点数量超过1000个。那么，对于节点数在1000以内的redis cluster集群，16384个槽位够用了。没有必要拓展到65536个。

（3）槽位越小，节点少的情况下，压缩比高，容易传输

Redis主节点的配置信息中它所负责的哈希槽是通过一张bitmap的形式来保存的，在传输过程中会对bitmap进行压缩，但是如果bitmap的填充率slots/ N很高的话（N表示节点数)，bitmap的压缩率就很低。如果节点数很少，而哈希槽数量很多的话，bitmap的压缩率就很低。

## Redis集群不保证强一致性，这意味着在特定的条件下，Redis集群可能会丢掉一些被系统收到的写入请求命令

**写安全性**：Redis集群在节点之间复制数据时，不是同步进行的，而是异步的。当某个节点出现故障时，集群会进行故障转移，并有一个隐含的合并功能，使得最后选定的主节点数据集会覆盖所有的从节点数据。这意味着在某些情况下，如果在数据分区时发生写入操作，这些写入的数据可能会丢失。

# 3主3从Redis集群搭建

集群3主3从，信息如下：

6个实例均是哨兵时所用的实例

| IP              | PORT | 角色   |
| --------------- | ---- | ------ |
| 192.168.122.132 | 6382 | master |
| 192.168.122.133 | 6383 | slave  |
| 192.168.122.134 | 6384 | master |
| 192.168.122.135 | 6385 | slave  |
| 192.168.122.136 | 6386 | master |
| 192.168.122.137 | 6387 | slave  |