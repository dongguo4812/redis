Redis6中hash的两种编码格式：ziplist、hashtable

Redis7中hash的两种编码格式：listpack、hashtable

# Redis6

```shell
127.0.0.1:6379> config get hash*
1) "hash-max-ziplist-entries"
2) "512"
3) "hash-max-ziplist-value"
4) "64"
```

**hash-max-ziplist-entries：使用压缩列表保存时哈希集合中的最大元素个数。**

**hash-max-ziplist-value：使用压缩列表保存时哈希集合中单个元素的最大长度。**

Hash结构默认采用OBJ_ENCODING_ ZipList编码，用以节省内存。

当

- ZipList中的元素数量超过了hash-max-ziplist-entries（默认512）
- ZipList中的任意entry大小超过了hash-max-ziplist-value（默认64字节）

前述条件任意一个不满足则会转换为 OBJ_ENCODING_HT的编码方式（hashtable）

Redis之所以这样设计，是因为当ziplist变得很⼤的时候，它有如下几个缺点：

- 每次插⼊或修改引发的realloc操作会有更⼤的概率造成内存拷贝，从而降低性能。
- ⼀旦发生内存拷贝，内存拷贝的成本也相应增加，因为要拷贝更⼤的⼀块数据。
- 当ziplist数据项过多的时候，在它上⾯查找指定的数据项就会性能变得很低，因为ziplist上的查找需要进行遍历。

总之，ziplist本来就设计为各个数据项挨在⼀起组成连续的内存空间，这种结构并不擅长做修改操作。⼀旦数据发⽣改动，就会引发内存realloc，可能导致内存拷贝。

![image-20240318164910971](https://gitee.com/dongguo4812_admin/image/raw/master/image/202403181826018.png)



![image-20240318164923617](https://gitee.com/dongguo4812_admin/image/raw/master/image/202403181826076.png)



ziplist可以升级到hashtable，hashtable无法降级为ziplist

一旦从压缩列表转为了哈希表，Hash类型就会一直用哈希表进行保存而不会再转回压缩列表了。

在节省内存空间方面哈希表就没有压缩列表高效了。







hash编码格式流程

![image-20240318164416983](https://gitee.com/dongguo4812_admin/image/raw/master/image/202403181826491.png)

## hashtable源码

在Redis中，hashtable被称为字典（dictionary），它是一个数组+链表的结构。Dict由三部分组成，分别是：哈希表（DictHashTable）、哈希节点（DictEntry）、字典（Dict）

![image-20240318170517693](https://gitee.com/dongguo4812_admin/image/raw/master/image/202403181826114.png)

OBJ_ENCODING_HT这种编码方式内部才是真正的哈希表结构,或称为字典结构,其可以实现O(1)复杂度的读写操作,因此效率很高。

在Redis内部，从OBJ_ENCODING_HT类型到底层真正的散列表数据结构是一层层嵌套下去的，组织关系见面图:

![image-20240318165644122](https://gitee.com/dongguo4812_admin/image/raw/master/image/202403181826850.png)

每个键值对都会有一个dictEntry

![image-20240318170606157](https://gitee.com/dongguo4812_admin/image/raw/master/image/202403181826835.png)



### dict.h

![image-20240318170431112](https://gitee.com/dongguo4812_admin/image/raw/master/image/202403181826901.png)



![image-20240318170442037](https://gitee.com/dongguo4812_admin/image/raw/master/image/202403181826360.png)



![image-20240318170450668](https://gitee.com/dongguo4812_admin/image/raw/master/image/202403181826571.png)



### hset 命令源码

![image-20240318170754673](https://gitee.com/dongguo4812_admin/image/raw/master/image/202403181826363.png)



编码判断转换

![image-20240318170811493](https://gitee.com/dongguo4812_admin/image/raw/master/image/202403181826843.png)

## ziplist

为了节约内存而开发的，它是由连续内存块组成的顺序型数据结构，有点类似于数组

ziplist是一个经过特殊编码的双向链表，是一种紧凑编码格式，它不存储指向前一个链表节点prev和指向下一个链表节点的指针next而是存储上一个节点长度和当前节点长度，通过牺牲部分读写性能，来换取高效的内存空间利用率，节约内存，是一种时间换空间的思想。只用在字段个数少，字段值小的场景里面。压缩列表内存利用率极高的原因与其连续内存的特性是分不开的。

### ziplist.h

ziplist的构成：

![image-20240318171330103](https://gitee.com/dongguo4812_admin/image/raw/master/image/202403181826492.png)









![image-20240318171353841](https://gitee.com/dongguo4812_admin/image/raw/master/image/202403181826341.png)



ziplist各个组成部分：

![image-20240318171405118](https://gitee.com/dongguo4812_admin/image/raw/master/image/202403181826306.png)

### zlentry 压缩列表节点的构成

ziplist中有多个zlentry，即entryx

**压缩列表zlentry节点结构：每个zlentry由前一个节点的长度、encoding和data三部分组成**

![image-20240318171615032](https://gitee.com/dongguo4812_admin/image/raw/master/image/202403181826995.png)

![image-20240318172907016](https://gitee.com/dongguo4812_admin/image/raw/master/image/202403181826844.png)

前节点：(前节点占用的内存字节数)表示前1个zlentry的长度，privious_entry_length有两种取值情况：1字节或5字节。取值1字节时，表示上一个entry的长度小于254字节。虽然1字节的值能表示的数值范围是0到255，但是压缩列表中zlend的取值默认是255，因此，就默认用255表示整个压缩列表的结束，其他表示长度的地方就不能再用255这个值了。所以，当上一个entry长度小于254字节时，prev_len取值为1字节，否则，就取值为5字节。记录长度的好处：占用内存小，1或者5个字节

enncoding：记录节点的content保存数据的类型和长度。

data：保存实际数据内容





### 为什么zlentry这么设计

prevlen，encoding长度都可以根据编码方式推算，真正变化的是data，而data长度记录在encoding里 ，因此entry的长度就知道了。entry总长度 = prevlen字节数+encoding字节数+data字节数

![image-20240318173237735](https://gitee.com/dongguo4812_admin/image/raw/master/image/202403181826324.png)

### 为什么记录前一个节点的长度？

链表在内存中，一般是不连续的，遍历相对比较慢，而ziplist可以很好的解决这个问题。如果知道了当前的起始地址，因为entry是连续的，entry后一定是另一个entry，想知道下一个entry的地址，只要将当前的起始地址加上当前entry总长度。如果还想遍历下一个entry，只要继续同样的操作。



### 明明有链表，为什么会涉及出压缩列表？

1 普通的双向链表会有两个指针，在存储数据很小的情况下，我们存储的实际数据的大小可能还没有指针占用的内存大，得不偿失。ziplist 是一个特殊的双向链表没有维护双向指针:previous next；而是存储上一个 entry的长度和当前entry的长度，通过长度推算下一个元素在什么地方。牺牲读取的性能，获得高效的存储空间，因为(简短字符串的情况)存储指针比存储entry长度更费内存。这是典型的“时间换空间”。

 

2 链表在内存中一般是不连续的，遍历相对比较慢而ziplist可以很好的解决这个问题，普通数组的遍历是根据数组里存储的数据类型找到下一个元素的(例如int类型的数组访问下一个元素时每次只需要移动一个sizeof(int)就行)，但是ziplist的每个节点的长度是可以不一样的，而我们面对不同长度的节点又不可能直接sizeof(entry)，所以ziplist只好将一些必要的偏移量信息记录在了每一个节点里，使之能跳到上一个节点或下一个节点。

备注:sizeof实际上是获取了数据在内存中所占用的存储空间，以字节为单位来计数。

 

3 头节点里有头节点里同时还有一个参数 len，和string类型提到的 SDS 类似，这里是用来记录链表长度的。因此获取链表长度时不用再遍历整个链表，直接拿到len值就可以了，这个时间复杂度是 O(1)



新增或更新元素可能会出现连锁更新现象(致命缺点导致ziplist被listpack替换)。

# Redis7

ziplist被listpack紧凑列表替代，为了兼容和过渡，依然保留ziplist的配置，修改listpack的配置，ziplist也会对应被修改。

**hash-max-listpack-entries：使用压缩列表保存时哈希集合中的最大元素个数。**

**hash-max-listpack-value：使用压缩列表保存时哈希集合中单个元素的最大长度。**

Hash类型键的字段个数 小于 hash-max-listpack-entries且每个字段名和字段值的长度 小于 hash-max-listpack-value 时，

Redis才会使用OBJ_ENCODING_LISTPACK来存储该键，前述条件任意一个不满足则会转换为 OBJ_ENCODING_HT的编码方式

![image-20240318174003944](https://gitee.com/dongguo4812_admin/image/raw/master/image/202403181826472.png)







![image-20240318174242355](https://gitee.com/dongguo4812_admin/image/raw/master/image/202403181826642.png)



listpack升级到hashtable可以,反过来降级不可以

流程同redis6，只不过ziplist修改为listpack

![image-20240318174526457](https://gitee.com/dongguo4812_admin/image/raw/master/image/202403181826233.png)



## 结构

![image-20240318175430054](https://gitee.com/dongguo4812_admin/image/raw/master/image/202403181826853.png)

| Total Bytes         | 为整个listpack的空间大小，占用4个字节，每个listpack最多占用4294967295Bytes。 |
| ------------------- | ------------------------------------------------------------ |
| num-elements        | 为listpack中的元素个数，即Entry的个数占用2个字节             |
| element-1~element-N | 为每个具体的元素                                             |
| listpack-end-byte   | 为listpack结束标志，占用1个字节，内容为0xFF。                |

![image-20240318175445126](https://gitee.com/dongguo4812_admin/image/raw/master/image/202403181826476.png)

### entry结构



和ziplist 列表项类似，listpack 列表项也包含了元数据信息和数据本身。不过，为了避免ziplist引起的连锁更新问题，listpack 中的每个列表项

![image-20240318180045669](https://gitee.com/dongguo4812_admin/image/raw/master/image/202403181826827.png)

不再像ziplist列表项那样保存其前一个列表项的长度。

![image-20240318175631296](https://gitee.com/dongguo4812_admin/image/raw/master/image/202403181827621.png)

entry-encoding 当前元素的编码类型

entry-data 元素数据

element-lot-len 编码类型和元素数据两部分的长度

## 源码

object.c中创建hash对象时默认使用listpack编码

先创建了一个空的listpack

![image-20240318174621692](https://gitee.com/dongguo4812_admin/image/raw/master/image/202403181827795.png)





listpack.c

![image-20240318174711687](https://gitee.com/dongguo4812_admin/image/raw/master/image/202403181827690.png)



IpNew函数创建了一个空的listpack,一开始分配的大小是LP_HDR_SIZE再加1个字节。LP_HDR_SIZE宏定义是在listpack.c中,它默认是6个字节,其中4个字节是记录listpack的总字节数, 2个字节是记录listpack的元素数量。此外， listpack 的最后一个字节是用来标识 listpack 的结束，其默认值是宏定义 LP_EOF。和 ziplist 列表项的结束标记一样，LP_EOF 的值也是 255



创建对象

![image-20240318174826493](https://gitee.com/dongguo4812_admin/image/raw/master/image/202403181827479.png)



### hash中已经有ziplist，为什么会被listpack紧凑列表替代？

ziplist的连锁更新问题



压缩列表新增某个元素或修改某个元素时，如果空间不不够，压缩列表占用的内存空间就需要重新分配。而当新插入的元素较大时，可能会导致后续元素的 prevlen 占用空间都发生变化，从而引起「连锁更新」问题，导致每个元素的空间都要重新分配，造成访问压缩列表性能的下降。

案例说明：**压缩列表每个节点正因为需要保存前一个节点的长度字段，就会有连锁更新的隐患**

第一步：现在假设一个压缩列表中有多个连续的、长度在 250～253 之间的节点，如下图：

![image-20240318175318793](https://gitee.com/dongguo4812_admin/image/raw/master/image/202403181827483.png)



因为这些节点长度值小于 254 字节，所以 prevlen 属性需要用 1 字节的空间来保存这个长度值





第二步：这时，如果将一个长度大于等于 254 字节的新节点加入到压缩列表的表头节点，即新节点将成为entry1的前置节点，如下图：

![image-20240318175337687](https://gitee.com/dongguo4812_admin/image/raw/master/image/202403181827644.png)

因为entry1节点的prevlen属性只有1个字节大小，无法保存新节点的长度，此时就需要对压缩列表的空间重分配操作并将entry1节点的prevlen 属性从原来的 1 字节大小扩展为 5 字节大小。



第三步：连续更新问题出现

![image-20240318175356569](https://gitee.com/dongguo4812_admin/image/raw/master/image/202403181827344.png)

entry1节点原本的长度在250～253之间，因为刚才的扩展空间，此时entry1节点的长度就大于等于254，因此原本entry2节点保存entry1节点的 prevlen属性也必须从1字节扩展至5字节大小。entry1节点影响entry2节点，entry2节点影响entry3节点......一直持续到结尾。这种在特殊情况下产生的连续多次空间扩展操作就叫做「连锁更新」

listpack 是 Redis 设计用来取代掉 ziplist 的数据结构，它通过每个节点记录自己的长度且放在节点的尾部，来彻底解决掉了 ziplist 存在的连锁更新的问题