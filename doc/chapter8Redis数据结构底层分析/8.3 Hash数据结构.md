Redis6中hash的两种编码格式：ziplist、hashtable

Redis7中hash的两种编码格式：listpack、hashtable

# Redis6

```shell
127.0.0.1:6379> config get hash*
1) "hash-max-ziplist-entries"
2) "512"
3) "hash-max-ziplist-value"
4) "64"
```

**hash-max-ziplist-entries：使用压缩列表保存时哈希集合中的最大元素个数。**

**hash-max-ziplist-value：使用压缩列表保存时哈希集合中单个元素的最大长度。**

Hash结构默认采用OBJ_ENCODING_ ZipList编码，用以节省内存。

当

- ZipList中的元素数量超过了hash-max-ziplist-entries（默认512）
- ZipList中的任意entry大小超过了hash-max-ziplist-value（默认64字节）

前述条件任意一个不满足则会转换为 OBJ_ENCODING_HT的编码方式（hashtable）

Redis之所以这样设计，是因为当ziplist变得很⼤的时候，它有如下几个缺点：

- 每次插⼊或修改引发的realloc操作会有更⼤的概率造成内存拷贝，从而降低性能。
- ⼀旦发生内存拷贝，内存拷贝的成本也相应增加，因为要拷贝更⼤的⼀块数据。
- 当ziplist数据项过多的时候，在它上⾯查找指定的数据项就会性能变得很低，因为ziplist上的查找需要进行遍历。

总之，ziplist本来就设计为各个数据项挨在⼀起组成连续的内存空间，这种结构并不擅长做修改操作。⼀旦数据发⽣改动，就会引发内存realloc，可能导致内存拷贝。

![image-20240318164910971](https://gitee.com/dongguo4812_admin/image/raw/master/image/202403181826018.png)



![image-20240318164923617](https://gitee.com/dongguo4812_admin/image/raw/master/image/202403181826076.png)



ziplist可以升级到hashtable，hashtable无法降级为ziplist

一旦从压缩列表转为了哈希表，Hash类型就会一直用哈希表进行保存而不会再转回压缩列表了。

在节省内存空间方面哈希表就没有压缩列表高效了。







hash编码格式流程

![image-20240318164416983](https://gitee.com/dongguo4812_admin/image/raw/master/image/202403181826491.png)

## hashtable源码（Dict）

在Redis中，hashtable被称为字典（dictionary,简称Dict），它是一个数组+链表的结构。Dict由三部分组成，分别是：哈希表（DictHashTable）、哈希节点（DictEntry）、字典（Dict）

![image-20240318170517693](https://gitee.com/dongguo4812_admin/image/raw/master/image/202403181826114.png)

dictht：DictHashTable



### 哈希冲突

当我们向Dict添加键值对时，redis首先根据key计算出hash值（h），然后利用h&sizemask来计算元素应该存储到数组中的那个索引位置。

![image-20240327111331438](https://gitee.com/dongguo4812_admin/image/raw/master/image/202403271113279.png)

我们存储hset k1 v1,假设k1的哈希值h=1，则1&3 = 1，因此k1要存储到数组角标1位置

![image-20240327111754055](https://gitee.com/dongguo4812_admin/image/raw/master/image/202403271117480.png)

存储hset k2 v2，假如k2计算的数组角标也使1，会将k2加入到数组角标1的队首

![image-20240327111735370](https://gitee.com/dongguo4812_admin/image/raw/master/image/202403271236763.png)



OBJ_ENCODING_HT这种编码方式内部才是真正的哈希表结构,或称为字典结构,其可以实现O(1)复杂度的读写操作,因此效率很高。

在Redis内部，从OBJ_ENCODING_HT类型到底层真正的散列表数据结构是一层层嵌套下去的，组织关系见面图:

![image-20240318165644122](https://gitee.com/dongguo4812_admin/image/raw/master/image/202403181826850.png)

每个键值对都会有一个dictEntry

![image-20240318170606157](https://gitee.com/dongguo4812_admin/image/raw/master/image/202403181826835.png)

### Dict的扩容

Dict的hashtable就是数组结合单向链表的实现，当集合中元素较多时，必然导致哈希冲突增多，链表过长，则查询效率会大大降低

Dict在每次新增键值对时都会检查负载因子(LoadFactor = used/size),满足一下两种情况时会触发哈希表扩容：

1.哈希表的loadFactor>=1，并且服务器没有执行BGSAVE或者BGREWRITEAOF等后台进程；

2.哈希表的loadFactor>5.

![image-20240327112705106](https://gitee.com/dongguo4812_admin/image/raw/master/image/202403271127193.png)

![image-20240327113309758](https://gitee.com/dongguo4812_admin/image/raw/master/image/202403271133873.png)

![image-20240327113407780](https://gitee.com/dongguo4812_admin/image/raw/master/image/202403271134015.png)

### Dict的收缩

dict除了扩容以外，每次删除元素时，也会对负载因子做检查，当loadFactor<0.1时，会做哈希表收缩

![image-20240327113000887](https://gitee.com/dongguo4812_admin/image/raw/master/image/202403271130075.png)

### Dict的rehash

不管是扩容还是收缩，必定会创建新的哈希表，导致哈希表的size和sizemask变化，而key的查询与sizemask有关。因此必须对哈希表中的每一个key重新计算索引，插入新的哈希表，这个过程称为rehash。过程是这样的：

- 计算新hash表的realeSize，值取决于当前要做的是扩容还是收缩：

- - 如果是扩容，则新size为第一个大于等于dict.ht[0].used + 1的2^n
  - 如果是收缩，则新size为第一个大于等于dict.ht[0].used的2^n （不得小于4）

- 按照新的realeSize申请内存空间，创建dictht，并赋值给dict.ht[1]

- 设置dict.rehashidx = 0，标示开始rehash

- 将dict.ht[0]中的每一个dictEntry都rehash到dict.ht[1]

- 将dict.ht[1]赋值给dict.ht[0]，给dict.ht[1]初始化为空哈希表，释放原来的dict.ht[0]的内存

![image-20240327113758866](https://gitee.com/dongguo4812_admin/image/raw/master/image/202403271138629.png)



添加k5 v5,申请8的内存空间

![image-20240327113907278](https://gitee.com/dongguo4812_admin/image/raw/master/image/202403271236538.png)

开始rehash，迁移dictEntry

![image-20240327114001935](https://gitee.com/dongguo4812_admin/image/raw/master/image/202403271236836.png)

赋值给ht[0]，rehash结束

![image-20240327114112138](https://gitee.com/dongguo4812_admin/image/raw/master/image/202403271236327.png)

rehash的风险

增删都要判断rehash，hash表存了数百万dictentry，rehash就会阻塞主线程

Dict的rehash并不是一次性完成的。试想一下,如果Dict中包含数百万的entry,要在一次rehash完成,极有可能导致主线程阻塞。因此Dict的rehash是分多次、渐进式的完成，因此称为**渐进式rehash**。流程如下：

- 计算新hash表的realeSize，值取决于当前要做的是扩容还是收缩：

- - 如果是扩容，则新size为第一个大于等于dict.ht[0].used + 1的2^n
  - 如果是收缩，则新size为第一个大于等于dict.ht[0].used的2^n （不得小于4

- 按照新的realeSize申请内存空间，创建dictht，并赋值给dict.ht[1]

- 设置dict.rehashidx = 0，标示开始rehash
- ~~将dict.ht[0]中的每一个dictEntry都rehash到dict.ht[1]~~
- 每次执行新增、查询、修改、删除操作时，都检查一下dict.rehashidx是否大于-1，如果是则将dict.ht[0].table[rehashidx]的entry链表rehash到dict.ht[1],并且将rehashidx++。直至dict.ht[0]的所有数据都rehash到dict.ht[1]

- 将dict.ht[1]赋值给dict.ht[0]，给dict.ht[1]初始化为空哈希表，释放原来的dict.ht[0]的内存
- 将rehashidx赋值为-1，代表rehash结束
- 在rehash过程中，新增操作，则直接写入ht[1]，查询、修改和删除则会在dict.ht[0]和dict.ht[1]依次查找并执行。这样可以确保ht[0]的数据只减不增，随着rehash最终为空

### dict.h

![image-20240318170431112](https://gitee.com/dongguo4812_admin/image/raw/master/image/202403181826901.png)



![image-20240318170442037](https://gitee.com/dongguo4812_admin/image/raw/master/image/202403181826360.png)



![image-20240318170450668](https://gitee.com/dongguo4812_admin/image/raw/master/image/202403181826571.png)



### hset 命令源码

![image-20240318170754673](https://gitee.com/dongguo4812_admin/image/raw/master/image/202403181826363.png)



编码判断转换

![image-20240318170811493](https://gitee.com/dongguo4812_admin/image/raw/master/image/202403181826843.png)

## ziplist

为了节约内存而开发的，它是由连续内存块组成的顺序型数据结构，有点类似于数组

ziplist是一个经过特殊编码的双向链表，是一种紧凑编码格式，它不存储指向前一个链表节点prev和指向下一个链表节点的指针next而是存储上一个节点长度和当前节点长度，通过牺牲部分读写性能，来换取高效的内存空间利用率，节约内存，是一种时间换空间的思想。只用在字段个数少，字段值小的场景里面。压缩列表内存利用率极高的原因与其连续内存的特性是分不开的。

### ziplist.h

ziplist的构成：

![image-20240318171330103](https://gitee.com/dongguo4812_admin/image/raw/master/image/202403181826492.png)









![image-20240318171353841](https://gitee.com/dongguo4812_admin/image/raw/master/image/202403181826341.png)



ziplist各个组成部分：

![image-20240318171405118](https://gitee.com/dongguo4812_admin/image/raw/master/image/202403181826306.png)

### zlentry 压缩列表节点的构成

ziplist中有多个zlentry，即entryx

**压缩列表zlentry节点结构：每个zlentry由前一个节点的长度、encoding和data三部分组成**

![image-20240318171615032](https://gitee.com/dongguo4812_admin/image/raw/master/image/202403181826995.png)

![image-20240318172907016](https://gitee.com/dongguo4812_admin/image/raw/master/image/202403181826844.png)

前节点：(前节点占用的内存字节数)表示前1个zlentry的长度，privious_entry_length有两种取值情况：1字节或5字节。取值1字节时，表示上一个entry的长度小于254字节。虽然1字节的值能表示的数值范围是0到255，但是压缩列表中zlend的取值默认是255，因此，就默认用255表示整个压缩列表的结束，其他表示长度的地方就不能再用255这个值了。所以，当上一个entry长度小于254字节时，prev_len取值为1字节，否则，就取值为5字节。记录长度的好处：占用内存小，1或者5个字节

enncoding：记录节点的content保存数据的类型和长度。

data：保存实际数据内容





### 为什么zlentry这么设计

prevlen，encoding长度都可以根据编码方式推算，真正变化的是data，而data长度记录在encoding里 ，因此entry的长度就知道了。entry总长度 = prevlen字节数+encoding字节数+data字节数

![image-20240318173237735](https://gitee.com/dongguo4812_admin/image/raw/master/image/202403181826324.png)

### 为什么记录前一个节点的长度？

链表在内存中，一般是不连续的，遍历相对比较慢，而ziplist可以很好的解决这个问题。如果知道了当前的起始地址，因为entry是连续的，entry后一定是另一个entry，想知道下一个entry的地址，只要将当前的起始地址加上当前entry总长度。如果还想遍历下一个entry，只要继续同样的操作。



### 明明有链表，为什么会涉及出压缩列表？

1 普通的双向链表会有两个指针，在存储数据很小的情况下，我们存储的实际数据的大小可能还没有指针占用的内存大，得不偿失。ziplist 是一个特殊的双向链表没有维护双向指针:previous next；而是存储上一个 entry的长度和当前entry的长度，通过长度推算下一个元素在什么地方。牺牲读取的性能，获得高效的存储空间，因为(简短字符串的情况)存储指针比存储entry长度更费内存。这是典型的“时间换空间”。

 

2 链表在内存中一般是不连续的，遍历相对比较慢而ziplist可以很好的解决这个问题，普通数组的遍历是根据数组里存储的数据类型找到下一个元素的(例如int类型的数组访问下一个元素时每次只需要移动一个sizeof(int)就行)，但是ziplist的每个节点的长度是可以不一样的，而我们面对不同长度的节点又不可能直接sizeof(entry)，所以ziplist只好将一些必要的偏移量信息记录在了每一个节点里，使之能跳到上一个节点或下一个节点。

备注:sizeof实际上是获取了数据在内存中所占用的存储空间，以字节为单位来计数。

 

3 头节点里有头节点里同时还有一个参数 len，和string类型提到的 SDS 类似，这里是用来记录链表长度的。因此获取链表长度时不用再遍历整个链表，直接拿到len值就可以了，这个时间复杂度是 O(1)



新增或更新元素可能会出现连锁更新现象(致命缺点导致ziplist被listpack替换)。

# Redis7

ziplist被listpack紧凑列表替代，为了兼容和过渡，依然保留ziplist的配置，修改listpack的配置，ziplist也会对应被修改。

**hash-max-listpack-entries：使用压缩列表保存时哈希集合中的最大元素个数。**

**hash-max-listpack-value：使用压缩列表保存时哈希集合中单个元素的最大长度。**

Hash类型键的字段个数 小于 hash-max-listpack-entries且每个字段名和字段值的长度 小于 hash-max-listpack-value 时，

Redis才会使用OBJ_ENCODING_LISTPACK来存储该键，前述条件任意一个不满足则会转换为 OBJ_ENCODING_HT的编码方式

![image-20240318174003944](https://gitee.com/dongguo4812_admin/image/raw/master/image/202403181826472.png)







![image-20240318174242355](https://gitee.com/dongguo4812_admin/image/raw/master/image/202403181826642.png)



listpack升级到hashtable可以,反过来降级不可以

流程同redis6，只不过ziplist修改为listpack

![image-20240318174526457](https://gitee.com/dongguo4812_admin/image/raw/master/image/202403181826233.png)



## 结构

![image-20240318175430054](https://gitee.com/dongguo4812_admin/image/raw/master/image/202403181826853.png)

| Total Bytes         | 为整个listpack的空间大小，占用4个字节，每个listpack最多占用4294967295Bytes。 |
| ------------------- | ------------------------------------------------------------ |
| num-elements        | 为listpack中的元素个数，即Entry的个数占用2个字节             |
| element-1~element-N | 为每个具体的元素                                             |
| listpack-end-byte   | 为listpack结束标志，占用1个字节，内容为0xFF。                |

![image-20240318175445126](https://gitee.com/dongguo4812_admin/image/raw/master/image/202403181826476.png)

### entry结构



和ziplist 列表项类似，listpack 列表项也包含了元数据信息和数据本身。不过，为了避免ziplist引起的连锁更新问题，listpack 中的每个列表项

![image-20240318180045669](https://gitee.com/dongguo4812_admin/image/raw/master/image/202403181826827.png)

不再像ziplist列表项那样保存其前一个列表项的长度。

![image-20240318175631296](https://gitee.com/dongguo4812_admin/image/raw/master/image/202403181827621.png)

entry-encoding 当前元素的编码类型

entry-data 元素数据

element-lot-len 编码类型和元素数据两部分的长度

## 源码

object.c中创建hash对象时默认使用listpack编码

先创建了一个空的listpack

![image-20240318174621692](https://gitee.com/dongguo4812_admin/image/raw/master/image/202403181827795.png)





listpack.c

![image-20240318174711687](https://gitee.com/dongguo4812_admin/image/raw/master/image/202403181827690.png)



IpNew函数创建了一个空的listpack,一开始分配的大小是LP_HDR_SIZE再加1个字节。LP_HDR_SIZE宏定义是在listpack.c中,它默认是6个字节,其中4个字节是记录listpack的总字节数, 2个字节是记录listpack的元素数量。此外， listpack 的最后一个字节是用来标识 listpack 的结束，其默认值是宏定义 LP_EOF。和 ziplist 列表项的结束标记一样，LP_EOF 的值也是 255



创建对象

![image-20240318174826493](https://gitee.com/dongguo4812_admin/image/raw/master/image/202403181827479.png)



### hash中已经有ziplist，为什么会被listpack紧凑列表替代？

ziplist的连锁更新问题



压缩列表新增某个元素或修改某个元素时，如果空间不不够，压缩列表占用的内存空间就需要重新分配。而当新插入的元素较大时，可能会导致后续元素的 prevlen 占用空间都发生变化，从而引起「连锁更新」问题，导致每个元素的空间都要重新分配，造成访问压缩列表性能的下降。

案例说明：**压缩列表每个节点正因为需要保存前一个节点的长度字段，就会有连锁更新的隐患**

第一步：现在假设一个压缩列表中有多个连续的、长度在 250～253 之间的节点，如下图：

![image-20240318175318793](https://gitee.com/dongguo4812_admin/image/raw/master/image/202403181827483.png)



因为这些节点长度值小于 254 字节，所以 prevlen 属性需要用 1 字节的空间来保存这个长度值





第二步：这时，如果将一个长度大于等于 254 字节的新节点加入到压缩列表的表头节点，即新节点将成为entry1的前置节点，如下图：

![image-20240318175337687](https://gitee.com/dongguo4812_admin/image/raw/master/image/202403181827644.png)

因为entry1节点的prevlen属性只有1个字节大小，无法保存新节点的长度，此时就需要对压缩列表的空间重分配操作并将entry1节点的prevlen 属性从原来的 1 字节大小扩展为 5 字节大小。



第三步：连续更新问题出现

![image-20240318175356569](https://gitee.com/dongguo4812_admin/image/raw/master/image/202403181827344.png)

entry1节点原本的长度在250～253之间，因为刚才的扩展空间，此时entry1节点的长度就大于等于254，因此原本entry2节点保存entry1节点的 prevlen属性也必须从1字节扩展至5字节大小。entry1节点影响entry2节点，entry2节点影响entry3节点......一直持续到结尾。这种在特殊情况下产生的连续多次空间扩展操作就叫做「连锁更新」

listpack 是 Redis 设计用来取代掉 ziplist 的数据结构，它通过每个节点记录自己的长度且放在节点的尾部，来彻底解决掉了 ziplist 存在的连锁更新的问题